<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="Say" id="2" localization="8" tooltip="Say some text. The text can be localized." x="985" y="237">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.tts = self.session().service('ALTextToSpeech')
        self.ttsStop = self.session().service('ALTextToSpeech') #Create another service as wait is blocking if audioout is remote
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += self.getParameter("Text")
            sentence +=  "\RST\ "
            id = self.tts.pCall("say",str("sentence"))
            self.ids.append(id)
            self.tts.wait(id)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Parameter name="Text" inherits_from_parent="0" content_type="5" value="Hello" default_value="" tooltip="The text you want to say. Don&apos;t forget to translate it!" id="7" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Box name="AskGpt" id="1" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="230" y="93">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import json
import time
from threading import Thread

try:
    from urllib.request import Request, urlopen
except ImportError:
    from urllib2 import Request, urlopen

AUDIO_FILE = "test.wav"

def call_chatgpt_api(prompt, api_key):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": "Bearer " + api_key,
        "Content-Type": "application/json"
    }
    data = json.dumps({
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 150,
        "temperature": 0.7
    }).encode('utf-8')

    try:
        request = Request(url, data=data, headers=headers)
        response = urlopen(request)
        result = json.load(response)
        return result['choices'][0]['message']['content']
    except Exception as e:
        return "Error calling ChatGPT API: " + str(e)  # Convert error to string

def transcribe_with_openai(file_path, api_key):
    url = "https://api.openai.com/v1/audio/transcriptions"
    boundary = "----WebKitFormBoundary7MA4YWxkTrZu0gW"
    headers = {
        "Authorization": "Bearer " + api_key,
        "Content-Type": "multipart/form-data; boundary=" + boundary
    }

    try:
        # Prepare the audio file as multipart/form-data
        with open(file_path, "rb") as audio_file:
            data = b''
            # Add file field
            data += "--" + boundary + "\r\n"
            data += "Content-Disposition: form-data; name=\"file\"; filename=\"" + AUDIO_FILE + "\"\r\n"
            data += "Content-Type: audio/wav\r\n\r\n"
            data += audio_file.read() + b"\r\n"

            # Add model field
            data += "--" + boundary + "\r\n"
            data += "Content-Disposition: form-data; name=\"model\"\r\n\r\n"
            data += "whisper-1\r\n"

            # End boundary
            data += "--" + boundary + "--\r\n"

        # Send the HTTP request
        request = Request(url, data=data, headers=headers)
        response = urlopen(request)
        result = json.load(response)

        # Return the transcription text
        return result.get("text", "No transcription found")
    except Exception as e:
        return "Error transcribing audio: " + str(e)  # Convert error to string


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        # Initialization code here
        self.tts = self.session().service('ALTextToSpeech')
        self.audiorec = self.session().service("ALAudioRecorder")
        self.audioplayer = self.session().service("ALAudioPlayer")
        pass

    def onUnload(self):
        # Clean-up code here
        pass

    def onInput_onStart(self):
        api_key = "sk-None-laWX0ykdQcVfNwieDXjjT3BlbkFJV2ZEwPrDdGc1MJXnDR2X"
        prompt = "Was ist die Haubtstadt von Deutschland?"
        channels = [0, 0, 1, 0]

        self.audiorec.startMicrophonesRecording("/home/nao/test.wav", "wav", 16000, channels);
        time.sleep(5)
        self.audiorec.stopMicrophonesRecording();

        text = transcribe_with_openai("/home/nao/test.wav", api_key)
        #self.say(text)

        #self.audioplayer.playFile("/home/nao/test.wav")
        self.delete_audio("/home/nao/test.wav")

        response = call_chatgpt_api(text, api_key)
        self.say(response)
        pass

    def onInput_onStop(self):
        self.onUnload()  # Reuse clean-up as the box is stopped
        self.onStopped()  # Activate the output of the box

    def on_text_input(self, value):
        print("User said:", value)
        # Process the text or send it to your ChatGPT function
        response = call_chatgpt_api(value, "sk-None-laWX0ykdQcVfNwieDXjjT3BlbkFJV2ZEwPrDdGc1MJXnDR2X")
        print("ChatGPT Response:", response)
        # You can also make the robot speak the response
        self.speak(response)

    def say(self, value):
        self.tts.pCall("say", str(value))

    def delete_audio(self, file_path):
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print("Deleted audio file: {file_path}")
            else:
                print("Audio file file_path does not exist.")
        except Exception as e:
            print("Error deleting audio file: {e}")]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Box name="GetVoice" id="3" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="684" y="207">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[def get_user_input():
    try:
        # Connect to ALMemory proxy
        memory = ALProxy("ALMemory", "127.0.0.1", 9559)

        # Connect to ALTextToSpeech proxy for feedback
        self.tts = self.session().service('ALTextToSpeech')

        self.tts.say("Please type your input in the dialog box.")

        # Monitor for input from the dialog box
        while True:
            user_input = memory.getData("Dialog/LastInput")
            if user_input:  # Check if input is available
                tts.say("You said: " + user_input)
                return user_input

            time.sleep(0.5)  # Avoid busy-waiting

    except Exception as e:
        print("Error: " + e)
        return None]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
